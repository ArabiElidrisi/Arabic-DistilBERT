{"payload":{"allShortcutsEnabled":true,"fileTree":{"":{"items":[{"name":"transformers","path":"transformers","contentType":"submodule","submoduleUrl":"/huggingface/transformers/tree/1cb059435e0bd2f2f28adc72df9341361265e1e8","submoduleDisplayName":"transformers @ 1cb0594"},{"name":".gitmodules","path":".gitmodules","contentType":"file"},{"name":"README.md","path":"README.md","contentType":"file"},{"name":"requirements.txt","path":"requirements.txt","contentType":"file"},{"name":"transformers.zip","path":"transformers.zip","contentType":"file"}],"totalCount":5}},"fileTreeProcessingTime":3.9154819999999995,"foldersToFetch":[],"reducedMotionEnabled":"system","repo":{"id":647527078,"defaultBranch":"main","name":"ArabBERT-KD","ownerLogin":"muhammed-saeed","currentUserCanPush":false,"isFork":false,"isEmpty":false,"createdAt":"2023-05-31T03:24:26.000+02:00","ownerAvatar":"https://avatars.githubusercontent.com/u/38116007?v=4","public":true,"private":false},"refInfo":{"name":"main","listCacheKey":"v0:1685503728.985728","canEdit":true,"refType":"branch","currentOid":"9ba60615e32e6beed61ded7f58e09bdb89771737"},"path":"README.md","currentUser":{"id":136182131,"login":"ArabiElidrisi","userEmail":"arabi.elidrisi@gmail.com"},"blob":{"rawBlob":null,"colorizedLines":null,"stylingDirectives":null,"csv":null,"csvError":null,"dependabotInfo":{"showConfigurationBanner":false,"configFilePath":null,"networkDependabotPath":"/muhammed-saeed/ArabBERT-KD/network/updates","dismissConfigurationNoticePath":"/settings/dismiss-notice/dependabot_configuration_notice","configurationNoticeDismissed":false,"repoAlertsPath":"/muhammed-saeed/ArabBERT-KD/security/dependabot","repoSecurityAndAnalysisPath":"/muhammed-saeed/ArabBERT-KD/settings/security_analysis","repoOwnerIsOrg":false,"currentUserCanAdminRepo":false},"displayName":"README.md","displayUrl":"https://github.com/muhammed-saeed/ArabBERT-KD/blob/main/README.md?raw=true","headerInfo":{"blobSize":"3.15 KB","deleteInfo":{"deletePath":"https://github.com/muhammed-saeed/ArabBERT-KD/delete/main/README.md","deleteTooltip":"Fork this repository and delete the file"},"editInfo":{"editTooltip":"Fork this repository and edit the file"},"ghDesktopPath":"https://desktop.github.com","gitLfsPath":null,"onBranch":true,"shortPath":"1b6b8da","siteNavLoginPath":"/login?return_to=https%3A%2F%2Fgithub.com%2Fmuhammed-saeed%2FArabBERT-KD%2Fblob%2Fmain%2FREADME.md","isCSV":false,"isRichtext":true,"toc":[{"level":1,"text":"Knowledge Distillation of BERT Language Model on the Arabic Language","anchor":"knowledge-distillation-of-bert-language-model-on-the-arabic-language","htmlText":"Knowledge Distillation of BERT Language Model on the Arabic Language"},{"level":2,"text":"Installation","anchor":"installation","htmlText":"Installation"},{"level":3,"text":"Requirements","anchor":"requirements","htmlText":"Requirements"},{"level":3,"text":"Environment","anchor":"environment","htmlText":"Environment"},{"level":3,"text":"2. Install transformers .","anchor":"2-install-transformers-","htmlText":"2. Install transformers ."},{"level":2,"text":"Training","anchor":"training","htmlText":"Training"},{"level":3,"text":"binarizating Data","anchor":"binarizating-data","htmlText":"binarizating Data"},{"level":3,"text":"Token counts","anchor":"token-counts","htmlText":"Token counts"},{"level":3,"text":"Train.py","anchor":"trainpy","htmlText":"Train.py"}],"lineInfo":{"truncatedLoc":"107","truncatedSloc":"83"},"mode":"file"},"image":false,"isCodeownersFile":null,"isValidLegacyIssueTemplate":false,"issueTemplateHelpUrl":"https://docs.github.com/articles/about-issue-and-pull-request-templates","issueTemplate":null,"discussionTemplate":null,"language":"Markdown","large":false,"loggedIn":true,"newDiscussionPath":"/muhammed-saeed/ArabBERT-KD/discussions/new","newIssuePath":"/muhammed-saeed/ArabBERT-KD/issues/new","planSupportInfo":{"repoIsFork":null,"repoOwnedByCurrentUser":null,"requestFullPath":"/muhammed-saeed/ArabBERT-KD/blob/main/README.md","showFreeOrgGatedFeatureMessage":null,"showPlanSupportBanner":null,"upgradeDataAttributes":null,"upgradePath":null},"publishBannersInfo":{"dismissActionNoticePath":"/settings/dismiss-notice/publish_action_from_dockerfile","dismissStackNoticePath":"/settings/dismiss-notice/publish_stack_from_file","releasePath":"/muhammed-saeed/ArabBERT-KD/releases/new?marketplace=true","showPublishActionBanner":false,"showPublishStackBanner":false},"renderImageOrRaw":false,"richText":"<article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><h1 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-knowledge-distillation-of-bert-language-model-on-the-arabic-language\" class=\"anchor\" aria-hidden=\"true\" href=\"#knowledge-distillation-of-bert-language-model-on-the-arabic-language\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>Knowledge Distillation of BERT Language Model on the Arabic Language</h1>\n<h2 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>Installation</h2>\n<h3 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"#requirements\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>Requirements</h3>\n<ul dir=\"auto\">\n<li>Python 3.8.16</li>\n</ul>\n<h3 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-environment\" class=\"anchor\" aria-hidden=\"true\" href=\"#environment\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>Environment</h3>\n<ol dir=\"auto\">\n<li>Create a virtual environment and activate it.</li>\n</ol>\n<p dir=\"auto\">python3 -m venv env\nsource env/bin/activate</p>\n<h3 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-2-install-transformers-\" class=\"anchor\" aria-hidden=\"true\" href=\"#2-install-transformers-\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>2. Install transformers .</h3>\n<p dir=\"auto\">we have cloned the transformer library and then modified the library to work with the arabic.</p>\n<p dir=\"auto\">The orignal transformers library link</p>\n<p dir=\"auto\"><code>https://github.com/huggingface/transformers</code></p>\n<p dir=\"auto\">but the <code>distillation</code> folder has been modified to work with the arabic models</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"cd transformes\npip install .\npip install -r transformers/examples/research_projects/distillation/requirements.txt\"><pre class=\"notranslate\"><code>cd transformes\npip install .\npip install -r transformers/examples/research_projects/distillation/requirements.txt\n</code></pre></div>\n<h2 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-training\" class=\"anchor\" aria-hidden=\"true\" href=\"#training\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>Training</h2>\n<h3 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-binarizating-data\" class=\"anchor\" aria-hidden=\"true\" href=\"#binarizating-data\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>binarizating Data</h3>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/binarized_data.py \\\n    --file_path arabic.txt \\\n    --tokenizer_type bert \\\n    --tokenizer_name asafaya/bert-large-arabic \\\n    --dump_file data/binarized_text\"><pre class=\"notranslate\"><code>python scripts/binarized_data.py \\\n    --file_path arabic.txt \\\n    --tokenizer_type bert \\\n    --tokenizer_name asafaya/bert-large-arabic \\\n    --dump_file data/binarized_text\n</code></pre></div>\n<h3 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-token-counts\" class=\"anchor\" aria-hidden=\"true\" href=\"#token-counts\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>Token counts</h3>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python scripts/token_counts.py \\\n    --data_file data/binarized_text.pickle \\\n    --token_counts_dump data/token_counts.pickle \\\n    --vocab_size 32000\"><pre class=\"notranslate\"><code>python scripts/token_counts.py \\\n    --data_file data/binarized_text.pickle \\\n    --token_counts_dump data/token_counts.pickle \\\n    --vocab_size 32000\n</code></pre></div>\n<h3 tabindex=\"-1\" dir=\"auto\"><a id=\"user-content-trainpy\" class=\"anchor\" aria-hidden=\"true\" href=\"#trainpy\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a>Train.py</h3>\n<p dir=\"auto\">using single GPU</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python train.py \\\n    --student_type distilbert \\\n    --student_config training_configs/distilbert-base-uncased.json \\\n    --teacher_type bert \\\n    --teacher_name asafaya/bert-large-arabic \\\n    --alpha_ce 5.0 --alpha_mlm 2.0 --alpha_cos 1.0 --alpha_clm 0.0 --mlm \\\n    --freeze_pos_embs \\\n    --dump_path distilbert_output/serialization_dir/my_first_training \\\n    --data_file data/binarized_text.pickle \\\n    --token_counts data/token_counts.pickle \\\n    --checkpoint_interval 100000 \\\n    --force # overwrites the `dump_path` if it already exists.\"><pre class=\"notranslate\"><code>python train.py \\\n    --student_type distilbert \\\n    --student_config training_configs/distilbert-base-uncased.json \\\n    --teacher_type bert \\\n    --teacher_name asafaya/bert-large-arabic \\\n    --alpha_ce 5.0 --alpha_mlm 2.0 --alpha_cos 1.0 --alpha_clm 0.0 --mlm \\\n    --freeze_pos_embs \\\n    --dump_path distilbert_output/serialization_dir/my_first_training \\\n    --data_file data/binarized_text.pickle \\\n    --token_counts data/token_counts.pickle \\\n    --checkpoint_interval 100000 \\\n    --force # overwrites the `dump_path` if it already exists.\n</code></pre></div>\n<p dir=\"auto\">Using multi GPU</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"export CUDA_VISIBLE_DEVICES=1,2\n\nexport NODE_RANK=0\nexport N_NODES=1\n\nexport N_GPU_NODE=2 # (CHANGE THIS ACCORDING TO YOUR GPUS)\nexport WORLD_SIZE=2 # (CHANGE THIS ACCORDING TO YOUR GPUS)\nexport MASTER_PORT=42562 # (you can use 29500)\nexport MASTER_ADDR=&quot;localhost&quot; # (leave as it is)\n\n\npkill -f 'python -u  transformers/examples/research_projects/distillation/train.py' # (CHANGE DEPENDING ON YOUR PATH)\n\npython -m torch.distributed.launch \\\n    --nproc_per_node=$N_GPU_NODE \\\n    --nnodes=$N_NODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT \\\n    transformers/examples/research_projects/distillation/train.py \n        --n_gpu $WORLD_SIZE \\\n        --student_type distilbert \\\n        --student_config transformers_/transformers/examples/research_projects/distillation/training_configs/distilbert-base-uncased.json \n        --student_pretrained_weights transformers/examples/research_projects/distillation/The_data/tf_bert-base-uncased_0247911.pth \n        --teacher_type bert \\\n        --teacher_name asafaya/bert-large-arabic \\\n        --alpha_ce 5.0 --alpha_mlm 2.0 --alpha_cos 1.0 --alpha_clm 0.0 --mlm \\\n        --freeze_pos_embs \\\n        --dump_path Dumps/ \n        --data_file transformers/examples/research_projects/distillation/The_data/merged_data_binarized.pickle \n        --token_counts transformers/examples/research_projects/distillation/The_data/merged_token_count.pickle \n        --batch_size 4 \n        --learning_rate 3e-5 \\\n        --checkpoint_interval 100000 \\\n        --force \"><pre class=\"notranslate\"><code>export CUDA_VISIBLE_DEVICES=1,2\n\nexport NODE_RANK=0\nexport N_NODES=1\n\nexport N_GPU_NODE=2 # (CHANGE THIS ACCORDING TO YOUR GPUS)\nexport WORLD_SIZE=2 # (CHANGE THIS ACCORDING TO YOUR GPUS)\nexport MASTER_PORT=42562 # (you can use 29500)\nexport MASTER_ADDR=\"localhost\" # (leave as it is)\n\n\npkill -f 'python -u  transformers/examples/research_projects/distillation/train.py' # (CHANGE DEPENDING ON YOUR PATH)\n\npython -m torch.distributed.launch \\\n    --nproc_per_node=$N_GPU_NODE \\\n    --nnodes=$N_NODES \\\n    --node_rank $NODE_RANK \\\n    --master_addr $MASTER_ADDR \\\n    --master_port $MASTER_PORT \\\n    transformers/examples/research_projects/distillation/train.py \n        --n_gpu $WORLD_SIZE \\\n        --student_type distilbert \\\n        --student_config transformers_/transformers/examples/research_projects/distillation/training_configs/distilbert-base-uncased.json \n        --student_pretrained_weights transformers/examples/research_projects/distillation/The_data/tf_bert-base-uncased_0247911.pth \n        --teacher_type bert \\\n        --teacher_name asafaya/bert-large-arabic \\\n        --alpha_ce 5.0 --alpha_mlm 2.0 --alpha_cos 1.0 --alpha_clm 0.0 --mlm \\\n        --freeze_pos_embs \\\n        --dump_path Dumps/ \n        --data_file transformers/examples/research_projects/distillation/The_data/merged_data_binarized.pickle \n        --token_counts transformers/examples/research_projects/distillation/The_data/merged_token_count.pickle \n        --batch_size 4 \n        --learning_rate 3e-5 \\\n        --checkpoint_interval 100000 \\\n        --force \n</code></pre></div>\n</article>","renderedFileInfo":null,"tabSize":8,"topBannersInfo":{"overridingGlobalFundingFile":false,"globalPreferredFundingPath":null,"repoOwner":"muhammed-saeed","repoName":"ArabBERT-KD","showInvalidCitationWarning":false,"citationHelpUrl":"https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-citation-files","showDependabotConfigurationBanner":false,"actionsOnboardingTip":null},"truncated":false,"viewable":true,"workflowRedirectUrl":null,"symbols":{"timedOut":false,"notAnalyzed":true,"symbols":[]}},"csrf_tokens":{"/muhammed-saeed/ArabBERT-KD/branches":{"post":"B_auVdu9jw9iD_KX7Bb6PzSmaGNbf14t2R3ERkiH6uBijdTQHY2a0dfAMSG64t2EYy_7GTujemSwCfo3TemROw"}}},"title":"ArabBERT-KD/README.md at main · muhammed-saeed/ArabBERT-KD","locale":"en"}